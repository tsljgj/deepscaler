++ /usr/bin/tclsh /usr/share/Modules/libexec/modulecmd.tcl bash load cuda-12.2
+ eval 'LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64:/data/user_data/mingkaid/open-r1/openr1/lib/python3.11/site-packages/nvidia/nvjitlink/lib; export LD_LIBRARY_PATH;
PATH=/usr/local/cuda-12.2/bin:/home/mingkaid/miniforge3/envs/deepscaler/bin:/home/mingkaid/.local/bin:/home/mingkaid/miniforge3/condabin:/home/mingkaid/.local/bin:/home/mingkaid/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin; export PATH;
CUDA_PATH=/usr/local/cuda-12.2; export CUDA_PATH;
_LMFILES_=/usr/share/Modules/modulefiles/cuda-12.2; export _LMFILES_;
LOADEDMODULES=cuda-12.2; export LOADEDMODULES;
test 0;'
++ LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64:/data/user_data/mingkaid/open-r1/openr1/lib/python3.11/site-packages/nvidia/nvjitlink/lib
++ export LD_LIBRARY_PATH
++ PATH=/usr/local/cuda-12.2/bin:/home/mingkaid/miniforge3/envs/deepscaler/bin:/home/mingkaid/.local/bin:/home/mingkaid/miniforge3/condabin:/home/mingkaid/.local/bin:/home/mingkaid/bin:/usr/share/Modules/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ export PATH
++ CUDA_PATH=/usr/local/cuda-12.2
++ export CUDA_PATH
++ _LMFILES_=/usr/share/Modules/modulefiles/cuda-12.2
++ export _LMFILES_
++ LOADEDMODULES=cuda-12.2
++ export LOADEDMODULES
++ test 0
+ _mlstatus=0
+ return 0
[36m(main_task pid=808917)[0m {'actor_rollout_ref': {'actor': {'clip_ratio': 0.2,
[36m(main_task pid=808917)[0m                                  'entropy_coeff': 0.001,
[36m(main_task pid=808917)[0m                                  'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=808917)[0m                                                  'grad_offload': False,
[36m(main_task pid=808917)[0m                                                  'optimizer_offload': False,
[36m(main_task pid=808917)[0m                                                  'param_offload': False,
[36m(main_task pid=808917)[0m                                                  'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=808917)[0m                                  'grad_clip': 1.0,
[36m(main_task pid=808917)[0m                                  'kl_loss_coef': 0.001,
[36m(main_task pid=808917)[0m                                  'kl_loss_type': 'low_var_kl',
[36m(main_task pid=808917)[0m                                  'optim': {'lr': 1e-06,
[36m(main_task pid=808917)[0m                                            'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=808917)[0m                                            'min_lr_ratio': None,
[36m(main_task pid=808917)[0m                                            'total_training_steps': -1,
[36m(main_task pid=808917)[0m                                            'warmup_style': 'constant'},
[36m(main_task pid=808917)[0m                                  'ppo_epochs': 1,
[36m(main_task pid=808917)[0m                                  'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=808917)[0m                                  'ppo_micro_batch_size': 64,
[36m(main_task pid=808917)[0m                                  'ppo_mini_batch_size': 64,
[36m(main_task pid=808917)[0m                                  'shuffle': False,
[36m(main_task pid=808917)[0m                                  'strategy': 'fsdp',
[36m(main_task pid=808917)[0m                                  'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=808917)[0m                                  'use_dynamic_bsz': True,
[36m(main_task pid=808917)[0m                                  'use_kl_loss': True},
[36m(main_task pid=808917)[0m                        'hybrid_engine': True,
[36m(main_task pid=808917)[0m                        'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=808917)[0m                                  'external_lib': None,
[36m(main_task pid=808917)[0m                                  'override_config': {},
[36m(main_task pid=808917)[0m                                  'path': '/data/user_data/mingkaid/models/Qwen2.5-3B',
[36m(main_task pid=808917)[0m                                  'use_remove_padding': True},
[36m(main_task pid=808917)[0m                        'ref': {'fsdp_config': {'param_offload': True,
[36m(main_task pid=808917)[0m                                                'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=808917)[0m                                'log_prob_max_token_len_per_gpu': 32768,
[36m(main_task pid=808917)[0m                                'log_prob_micro_batch_size': 128,
[36m(main_task pid=808917)[0m                                'log_prob_use_dynamic_bsz': True,
[36m(main_task pid=808917)[0m                                'ulysses_sequence_parallel_size': 1},
[36m(main_task pid=808917)[0m                        'rollout': {'do_sample': True,
[36m(main_task pid=808917)[0m                                    'dtype': 'bfloat16',
[36m(main_task pid=808917)[0m                                    'enable_chunked_prefill': True,
[36m(main_task pid=808917)[0m                                    'enforce_eager': True,
[36m(main_task pid=808917)[0m                                    'free_cache_engine': True,
[36m(main_task pid=808917)[0m                                    'gpu_memory_utilization': 0.85,
[36m(main_task pid=808917)[0m                                    'ignore_eos': False,
[36m(main_task pid=808917)[0m                                    'load_format': 'dummy_dtensor',
[36m(main_task pid=808917)[0m                                    'log_prob_max_token_len_per_gpu': 32768,
[36m(main_task pid=808917)[0m                                    'log_prob_micro_batch_size': 128,
[36m(main_task pid=808917)[0m                                    'log_prob_use_dynamic_bsz': True,
[36m(main_task pid=808917)[0m                                    'max_num_batched_tokens': 8192,
[36m(main_task pid=808917)[0m                                    'max_num_seqs': 1024,
[36m(main_task pid=808917)[0m                                    'n': 8,
[36m(main_task pid=808917)[0m                                    'n_val': 8,
[36m(main_task pid=808917)[0m                                    'name': 'vllm',
[36m(main_task pid=808917)[0m                                    'prompt_length': 1024,
[36m(main_task pid=808917)[0m                                    'response_length': 8192,
[36m(main_task pid=808917)[0m                                    'temperature': 0.6,
[36m(main_task pid=808917)[0m                                    'tensor_model_parallel_size': 1,
[36m(main_task pid=808917)[0m                                    'top_k': -1,
[36m(main_task pid=808917)[0m                                    'top_p': 1,
[36m(main_task pid=808917)[0m                                    'val_temperature': 0.6}},
[36m(main_task pid=808917)[0m  'algorithm': {'adv_estimator': 'grpo',
[36m(main_task pid=808917)[0m                'gamma': 1.0,
[36m(main_task pid=808917)[0m                'kl_ctrl': {'kl_coef': 0.001, 'type': 'fixed'},
[36m(main_task pid=808917)[0m                'kl_penalty': 'kl',
[36m(main_task pid=808917)[0m                'lam': 1.0},
[36m(main_task pid=808917)[0m  'critic': {'cliprange_value': 0.5,
[36m(main_task pid=808917)[0m             'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=808917)[0m             'forward_micro_batch_size': 64,
[36m(main_task pid=808917)[0m             'grad_clip': 1.0,
[36m(main_task pid=808917)[0m             'model': {'enable_gradient_checkpointing': True,
[36m(main_task pid=808917)[0m                       'external_lib': None,
[36m(main_task pid=808917)[0m                       'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=808917)[0m                                       'grad_offload': False,
[36m(main_task pid=808917)[0m                                       'optimizer_offload': False,
[36m(main_task pid=808917)[0m                                       'param_offload': False,
[36m(main_task pid=808917)[0m                                       'wrap_policy': {'min_num_params': 0}},
[36m(main_task pid=808917)[0m                       'override_config': {},
[36m(main_task pid=808917)[0m                       'path': '~/models/deepseek-llm-7b-chat',
[36m(main_task pid=808917)[0m                       'tokenizer_path': '/data/user_data/mingkaid/models/Qwen2.5-3B',
[36m(main_task pid=808917)[0m                       'use_remove_padding': False},
[36m(main_task pid=808917)[0m             'optim': {'lr': 1e-05,
[36m(main_task pid=808917)[0m                       'lr_warmup_steps_ratio': 0.0,
[36m(main_task pid=808917)[0m                       'min_lr_ratio': None,
[36m(main_task pid=808917)[0m                       'total_training_steps': -1,
[36m(main_task pid=808917)[0m                       'warmup_style': 'constant'},
[36m(main_task pid=808917)[0m             'ppo_epochs': 1,
[36m(main_task pid=808917)[0m             'ppo_max_token_len_per_gpu': 32768,
[36m(main_task pid=808917)[0m             'ppo_micro_batch_size': 64,
[36m(main_task pid=808917)[0m             'ppo_mini_batch_size': 64,
[36m(main_task pid=808917)[0m             'shuffle': False,
[36m(main_task pid=808917)[0m             'strategy': 'fsdp',
[36m(main_task pid=808917)[0m             'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=808917)[0m             'use_dynamic_bsz': True},
[36m(main_task pid=808917)[0m  'data': {'max_prompt_length': 1024,
[36m(main_task pid=808917)[0m           'max_response_length': 8192,
[36m(main_task pid=808917)[0m           'prompt_key': 'prompt',
[36m(main_task pid=808917)[0m           'return_raw_chat': False,
[36m(main_task pid=808917)[0m           'return_raw_input_ids': False,
[36m(main_task pid=808917)[0m           'tokenizer': None,
[36m(main_task pid=808917)[0m           'train_batch_size': 128,
[36m(main_task pid=808917)[0m           'train_files': '/home/mingkaid/deepscaler/data/train.parquet',
[36m(main_task pid=808917)[0m           'val_batch_size': 512,
[36m(main_task pid=808917)[0m           'val_files': '/home/mingkaid/deepscaler/data/aime.parquet'},
[36m(main_task pid=808917)[0m  'reward_model': {'enable': False,
[36m(main_task pid=808917)[0m                   'forward_max_token_len_per_gpu': 32768,
[36m(main_task pid=808917)[0m                   'max_length': None,
[36m(main_task pid=808917)[0m                   'micro_batch_size': 64,
[36m(main_task pid=808917)[0m                   'model': {'external_lib': None,
[36m(main_task pid=808917)[0m                             'fsdp_config': {'fsdp_size': -1,
[36m(main_task pid=808917)[0m                                             'min_num_params': 0,
[36m(main_task pid=808917)[0m                                             'param_offload': False},
[36m(main_task pid=808917)[0m                             'input_tokenizer': '/data/user_data/mingkaid/models/Qwen2.5-3B',
[36m(main_task pid=808917)[0m                             'path': '~/models/FsfairX-LLaMA3-RM-v0.1',
[36m(main_task pid=808917)[0m                             'use_remove_padding': False},
[36m(main_task pid=808917)[0m                   'strategy': 'fsdp',
[36m(main_task pid=808917)[0m                   'ulysses_sequence_parallel_size': 1,
[36m(main_task pid=808917)[0m                   'use_dynamic_bsz': True},
[36m(main_task pid=808917)[0m  'trainer': {'critic_warmup': 0,
[36m(main_task pid=808917)[0m              'default_hdfs_dir': None,
[36m(main_task pid=808917)[0m              'default_local_dir': 'checkpoints/deepscaler/deepscaler-1.5b-8k',
[36m(main_task pid=808917)[0m              'experiment_name': 'deepscaler-1.5b-8k',
[36m(main_task pid=808917)[0m              'logger': ['console', 'wandb'],
[36m(main_task pid=808917)[0m              'n_gpus_per_node': 4,
[36m(main_task pid=808917)[0m              'nnodes': 1,
[36m(main_task pid=808917)[0m              'project_name': 'deepscaler',
[36m(main_task pid=808917)[0m              'rejection_sample': False,
[36m(main_task pid=808917)[0m              'rejection_sample_multiplier': 2,
[36m(main_task pid=808917)[0m              'save_freq': 20,
[36m(main_task pid=808917)[0m              'test_freq': 20,
[36m(main_task pid=808917)[0m              'total_epochs': 30,
[36m(main_task pid=808917)[0m              'total_training_steps': None,
[36m(main_task pid=808917)[0m              'val_before_train': True}}
[36m(main_task pid=808917)[0m original dataset len: 40315
[36m(main_task pid=808917)[0m filter dataset len: 40306
[36m(main_task pid=808917)[0m original dataset len: 30
[36m(main_task pid=808917)[0m filter dataset len: 30
[36m(main_task pid=808917)[0m Size of train dataloader: 314
[36m(main_task pid=808917)[0m Size of val dataloader: 1
[36m(main_task pid=808917)[0m Total training steps: 9420
[36m(WorkerDict pid=809386)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=809386)[0m   "_name_or_path": "/data/user_data/mingkaid/models/Qwen2.5-3B",
[36m(WorkerDict pid=809386)[0m   "architectures": [
[36m(WorkerDict pid=809386)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=809386)[0m   ],
[36m(WorkerDict pid=809386)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=809386)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=809386)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=809386)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=809386)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=809386)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=809386)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=809386)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=809386)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=809386)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=809386)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=809386)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=809386)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=809386)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=809386)[0m   "rope_scaling": null,
[36m(WorkerDict pid=809386)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=809386)[0m   "sliding_window": null,
[36m(WorkerDict pid=809386)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=809386)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=809386)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=809386)[0m   "use_cache": true,
[36m(WorkerDict pid=809386)[0m   "use_mrope": false,
[36m(WorkerDict pid=809386)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=809386)[0m   "vocab_size": 151936
[36m(WorkerDict pid=809386)[0m }
[36m(WorkerDict pid=809386)[0m 
[36m(WorkerDict pid=809386)[0m NCCL version 2.20.5+cuda12.4
[36m(WorkerDict pid=809386)[0m Qwen2ForCausalLM contains 3.09B parameters
[36m(WorkerDict pid=809386)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7f2888c6d090>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})
[36m(WorkerDict pid=809386)[0m Actor use_remove_padding=True
[36m(WorkerDict pid=809612)[0m wrap_policy: functools.partial(<function transformer_auto_wrap_policy at 0x7f3729fa1090>, transformer_layer_cls={<class 'transformers.models.qwen2.modeling_qwen2.Qwen2DecoderLayer'>})[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(WorkerDict pid=809386)[0m Model config after override: Qwen2Config {
[36m(WorkerDict pid=809386)[0m   "_name_or_path": "/data/user_data/mingkaid/models/Qwen2.5-3B",
[36m(WorkerDict pid=809386)[0m   "architectures": [
[36m(WorkerDict pid=809386)[0m     "Qwen2ForCausalLM"
[36m(WorkerDict pid=809386)[0m   ],
[36m(WorkerDict pid=809386)[0m   "attention_dropout": 0.0,
[36m(WorkerDict pid=809386)[0m   "eos_token_id": 151643,
[36m(WorkerDict pid=809386)[0m   "hidden_act": "silu",
[36m(WorkerDict pid=809386)[0m   "hidden_size": 2048,
[36m(WorkerDict pid=809386)[0m   "initializer_range": 0.02,
[36m(WorkerDict pid=809386)[0m   "intermediate_size": 11008,
[36m(WorkerDict pid=809386)[0m   "max_position_embeddings": 32768,
[36m(WorkerDict pid=809386)[0m   "max_window_layers": 36,
[36m(WorkerDict pid=809386)[0m   "model_type": "qwen2",
[36m(WorkerDict pid=809386)[0m   "num_attention_heads": 16,
[36m(WorkerDict pid=809386)[0m   "num_hidden_layers": 36,
[36m(WorkerDict pid=809386)[0m   "num_key_value_heads": 2,
[36m(WorkerDict pid=809386)[0m   "pad_token_id": 151643,
[36m(WorkerDict pid=809386)[0m   "rms_norm_eps": 1e-06,
[36m(WorkerDict pid=809386)[0m   "rope_scaling": null,
[36m(WorkerDict pid=809386)[0m   "rope_theta": 1000000.0,
[36m(WorkerDict pid=809386)[0m   "sliding_window": null,
[36m(WorkerDict pid=809386)[0m   "tie_word_embeddings": true,
[36m(WorkerDict pid=809386)[0m   "torch_dtype": "bfloat16",
[36m(WorkerDict pid=809386)[0m   "transformers_version": "4.47.1",
[36m(WorkerDict pid=809386)[0m   "use_cache": true,
[36m(WorkerDict pid=809386)[0m   "use_mrope": false,
[36m(WorkerDict pid=809386)[0m   "use_sliding_window": false,
[36m(WorkerDict pid=809386)[0m   "vocab_size": 151936
[36m(WorkerDict pid=809386)[0m }
[36m(WorkerDict pid=809386)[0m 
[33m(raylet)[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff0b44c67f28b517501fa96d8001000000 Worker ID: 9810f663d26557644599b8e7bd377e0226c031ac34c0de17ec417437 Node ID: 7739de0a76d9fde3166d1ed918d88c5c03c380ae6e9f00d86a578677 Worker IP address: 10.1.1.24 Worker port: 36061 Worker PID: 809611 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.
[36m(WorkerDict pid=809612)[0m Actor use_remove_padding=True[32m [repeated 3x across cluster][0m
